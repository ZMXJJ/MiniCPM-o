# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, OpenBMB
# This file is distributed under the same license as the MiniCPM-o Cookbook
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MiniCPM-o Cookbook \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-07-15 18:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/quantization/bnb.md:1 b23e32764164428a9ada82273beac885
msgid "BNB"
msgstr "BNB"

#: ../../source/quantization/bnb.md:4 4c40a03cb02943398539a1d0de636ab1
msgid "**Support:** MiniCPM-V4.0 / MiniCPM-V2.6 / MiniCPM-V2.5"
msgstr "**支持模型:** MiniCPM-V4.0 / MiniCPM-V2.6 / MiniCPM-V2.5"

#: ../../source/quantization/bnb.md:8 f31bcbc60e69416a8c4a941ac57dd851
msgid "1. Download the Model"
msgstr "1. 下载模型"

#: ../../source/quantization/bnb.md:10 0767ed228b1d40ec89ae8b79f85f03aa
msgid ""
"Download the MiniCPM-V-4 model from "
"[HuggingFace](https://huggingface.co/openbmb/MiniCPM-V-4) and extract it "
"to your local directory."
msgstr "从[HuggingFace](https://huggingface.co/openbmb/MiniCPM-V-4)下载MiniCPM-V-4模型并解压到本地目录。"

#: ../../source/quantization/bnb.md:12 b3da7cfc2e3f4489ad863747a0126d6e
msgid "2. Quantization Script"
msgstr "2. 量化脚本"

#: ../../source/quantization/bnb.md:14 500af945e62b48a19a53eabc6cceba3e
msgid ""
"The following script loads the original model, quantizes it to 4-bit "
"using bitsandbytes, and saves the quantized model."
msgstr "以下脚本加载原始模型，使用bitsandbytes将其量化为4比特，并保存量化后的模型。"

#: ../../source/quantization/bnb.md:75 67cd7c4eb0d543a28429565ccd86b910
msgid "3. Expected Output"
msgstr "3. 预期输出"

#: ../../source/quantization/bnb.md:77 1c1f5ed8af5c41b087b673d619259607
msgid "After quantization, you should see output similar to:"
msgstr "量化完成后，你应该会看到类似如下的输出："

#: ../../source/quantization/bnb.md:85 08a563af9a0b4ac1a37837b0978407b4
msgid ""
"The quantized model will be saved in the directory specified by "
"`save_path` and can be used for further fine-tuning or inference."
msgstr "量化后的模型将保存在`save_path`指定的目录下，可用于后续微调或推理。"

#: ../../source/quantization/bnb.md:88 89aec0fdb84248868f969d8c9dbe9573
msgid ""
"To customize the model path, image, or save path, modify the "
"corresponding variables in the script."
msgstr "如需自定义模型路径、镜像或保存路径，请修改脚本中的相关变量。"
