# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, OpenBMB
# This file is distributed under the same license as the MiniCPM-o Cookbook
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MiniCPM-o Cookbook \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-07-17 19:58+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/quantization/gguf.md:1 4cad9ad18ab54756bcbc177aec0c0fd9
msgid "GGUF"
msgstr "GGUF"

#: ../../source/quantization/gguf.md:4 8a53a88e6eac44a1ba4bdef8f83574dd
msgid "**Support:** MiniCPM-V4.0 / MiniCPM-V2.6 / MiniCPM-V2.5"
msgstr "**支持模型:** MiniCPM-V2.6 / MiniCPM-V 2.5"

#: ../../source/quantization/gguf.md:7 5a8e1b2128ce4972a4086902760d7eae
msgid "1.Download the PyTorch Model"
msgstr "1.下载 PyTorch 模型"

#: ../../source/quantization/gguf.md:9 5537ac332a82445fbb3fcf5ceddeaf62
msgid ""
"First, obtain the original PyTorch model files from one of the following "
"sources:"
msgstr "首先，从以下来源之一获取原始的 PyTorch 模型文件："

#: ../../source/quantization/gguf.md:11 37c07d05683a4946b0657964a3efaec8
msgid "**HuggingFace:** https://huggingface.co/openbmb/MiniCPM-V-4"
msgstr "**[HuggingFace](https://huggingface.co/openbmb/MiniCPM-V-2_6)**"

#: ../../source/quantization/gguf.md:12 e5808694aec3400b93d2303c5b4aba21
msgid "**ModelScope Community:** https://modelscope.cn/models/OpenBMB/MiniCPM-V-4"
msgstr "**[ModelScope](https://modelscope.cn/models/OpenBMB/MiniCPM-V-2_6)**"

#: ../../source/quantization/gguf.md:14 06abca6b3a0b41b9b55909823c4a2936
msgid "2.Convert the PyTorch Model to GGUF Format"
msgstr "2.将 PyTorch 模型转换为 GGUF 格式"

#: ../../source/quantization/gguf.md:16 5ef90d0403764e9dba897567fbbedd46
msgid ""
"Run the following commands in sequence to perform model surgery, convert "
"the vision encoder, and then convert the language model."
msgstr "依次运行以下命令以进行模型结构调整、转换视觉编码器，然后转换语言模型。"

#: ../../source/quantization/gguf.md:29 5bb40e3350074dd49afb4429fc9ace48
msgid "3.Perform INT4 Quantization"
msgstr "3.执行 INT4 量化"

#: ../../source/quantization/gguf.md:31 09b1ed3aa78e406dbfaec0bab0146f8c
msgid ""
"Once the conversion is complete, use the `llama-quantize` tool to "
"quantize the F16 precision GGUF model to INT4."
msgstr "转换完成后，使用 `llama-quantize` 工具将 F16 精度的 GGUF 模型量化为 INT4。"

#~ msgid "To be updated for MiniCPM-V 4.0"
#~ msgstr "即将支持 MiniCPM-V 4.0"

