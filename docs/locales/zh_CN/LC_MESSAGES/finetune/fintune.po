# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, OpenBMB
# This file is distributed under the same license as the MiniCPM-o Cookbook
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MiniCPM-o Cookbook \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-07-20 15:43+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/finetune/fintune.md:1 4a9c9fa2d7844be9aaa0542cea0d3c80
msgid "Finetune"
msgstr "微调"

#: ../../source/finetune/fintune.md:4 17e78377dc354fb7bd5f4cfb8f26e171
msgid ""
"We provide official scripts for easily fine-tuning the pretrained models "
"**MiniCPM-V 4.0**, **MiniCPM-o 2.6**, **MiniCPM-V 2.6**, **MiniCPM-"
"Llama3-V 2.5**, and **MiniCPM-V 2.0** on downstream tasks. The fine-"
"tuning scripts use `transformers Trainer` and `DeepSpeed` by default."
msgstr ""
"我们提供官方脚本，可以轻松地在下游任务上微调预训练模型 "
"**MiniCPM-V 4.0**、**MiniCPM-o 2.6**、**MiniCPM-V 2.6**、**MiniCPM-Llama3-V "
"2.5** 和 **MiniCPM-V 2.0**。微调脚本默认使用 `transformers Trainer` 和 `DeepSpeed`。"

#: ../../source/finetune/fintune.md:6 b8409786193a4d2fa78b7f51b2149c3f
msgid "This section takes **MiniCPM-o 2.6** as an example."
msgstr "本节以 **MiniCPM-o2.6** 为例。"

#: ../../source/finetune/fintune.md:10 5f5558893cb74ae9b69ebdcb5c858e2b
msgid "Data preparation"
msgstr "数据准备"

#: ../../source/finetune/fintune.md:12 a6a48b4c618c4423b749f14cf94852bc
msgid ""
"To prepare your fine-tuning data, you should formulate each sample as a "
"dictionary consisting of an id, an image path (or list of images), and a "
"list of conversations. Then, save the data samples in JSON files."
msgstr "要准备微调数据，您应将每个样本格式化为一个字典，其中包含 ID、图像路径（或图像列表）和对话列表。然后，将数据样本保存在 JSON 文件中。"

#: ../../source/finetune/fintune.md:14 8bbe5ecf36c44a4eb03c369f8f52a751
msgid ""
"For vision-language tasks, you must provide placeholders like "
"**\\<image\\>** or **\\<image_XX\\>** to define where to insert the image"
" embeddings within the conversation. If no placeholder is provided, the "
"image will be placed at the front of the conversation by default."
msgstr ""
"对于视觉语言任务，您必须提供像 **\\<image\\>** 或 **\\<image_XX\\>** "
"这样的占位符，以定义在对话中插入图像嵌入的位置。如果未提供占位符，默认情况下图像将放置在对话的开头。"

#: ../../source/finetune/fintune.md:16 4559d5389cc340df8e9c640c89ec35f8
msgid "Single Image Example"
msgstr "单张图片示例"

#: ../../source/finetune/fintune.md:17 9afbc36bed19459ebdc547e30c5cf19b
msgid ""
"If your input consists of a single image, you can use a single "
"placeholder **\\<image\\>** to indicate where the image should be "
"inserted in the conversation."
msgstr "如果您的输入包含单张图像，您可以使用单个占位符 **\\<image\\>** 来指示图像应插入对话中的位置。"

#: ../../source/finetune/fintune.md:59 de2bfbbecffa4850ab779a70de5620df
msgid "Multiple Images Example"
msgstr "多张图片示例"

#: ../../source/finetune/fintune.md:60 4db67d776940420bbb68d798013c9ae0
msgid ""
"For inputs containing multiple images, utilize a dictionary where each "
"key represents a unique placeholder (e.g., **\\<image_00\\>**, "
"**\\<image_01\\**) with the corresponding image path as its value. These "
"placeholders can then be used within the conversation to seamlessly "
"insert images at specific positions."
msgstr "对于包含多张图像的输入，请使用一个字典，其中每个键代表一个唯一的占位符（例如，**\\<image_00\\>**、**\\<image_01\\>**），其值为相应的图像路径。然后，这些占位符可以在对话中使用，以在特定位置无缝插入图像。"

#: ../../source/finetune/fintune.md:62 bb6ea46769d54362bdda3cfc0b08918d
msgid ""
"Additionally, to optimize resource management, especially when dealing "
"with large batches of images during training or inference, consider "
"reducing `max_slice_nums`. For example, in version 2.6, a single image is"
" represented by 64 tokens. When `slice=9`, an image with a maximum "
"resolution of 1344x1344 will consume nearly 64*(9+1) tokens. To minimize "
"the number of tokens used per image, you can set `slice=1`, resulting in "
"a single image being represented by 64 tokens."
msgstr ""
"此外，为了优化资源管理，尤其是在训练或推理期间处理大量图像时，请考虑减少 `max_slice_nums`。例如，在 2.6 版本中，一张图像由 "
"64 个 token 表示。当 `slice=9` 时，最大分辨率为 1344x1344 的图像将消耗近 64*(9+1) 个 "
"token。为了最小化每张图像使用的 token 数量，您可以设置 `slice=1`，这样一张图像就由 64 个 token 表示。"

#: ../../source/finetune/fintune.md:64 3ea49fcf5036469592990ea3ebe605b0
msgid ""
"If the total token count exceeds `max_length`, truncation will be "
"applied. For multi-image supervised fine-tuning (SFT), it's recommended "
"to set `MODEL_MAX_LENGTH=4096` in your script for better performance."
msgstr ""
"如果总 token 数量超过 `max_length`，将进行截断。对于多图像监督微调（SFT），建议在脚本中设置 "
"`MODEL_MAX_LENGTH=4096` 以获得更好的性能。"

#: ../../source/finetune/fintune.md:98 fd13a4d409a142a78f07a8ed30187a30
msgid "Full-parameter finetuning"
msgstr "全参数微调"

#: ../../source/finetune/fintune.md:100 c782e5099f1048e3837bccfc548500f7
msgid ""
"Full-parameter parameter finetuning requires updating all parameters of "
"LLM in the whole training process. Please specify the correct MODEL path,"
" DATA path and LLM_TYPE in the shell scripts."
msgstr "全参数微调需要在整个训练过程中更新 LLM 的所有参数。请在 shell 脚本中指定正确的 MODEL 路径、DATA 路径和 LLM_TYPE。"

#: ../../source/finetune/fintune.md:110 8ff273950a674b4eb71ad24331b963c3
msgid "To launch your training, run the following script:"
msgstr "要启动训练，请运行以下脚本："

#: ../../source/finetune/fintune.md:117 b76e4cbea8094af3a2264b84a5ce6527
msgid "LoRA finetuning"
msgstr "LoRA 微调"

#: ../../source/finetune/fintune.md:119 eab2c083fe0043a48b538d8be6b8bdca
msgid ""
"The LoRA allows light-weight model tuning with only a small subset of "
"parameters updated. We provide the LoRA implementation based on `peft`. "
"To launch your training, run the following script:"
msgstr "LoRA 允许轻量级模型微调，只需更新一小部分参数。我们提供了基于 `peft` 的 LoRA 实现。要启动训练，请运行以下脚本："

#: ../../source/finetune/fintune.md:125 6e813b2362e443629df38d383277f540
msgid ""
"After training, you could load the model with the path to the adapter. We"
" advise you to use absolute path for your pretrained model. This is "
"because LoRA only saves the adapter and the absolute path in the adapter "
"configuration json file is used for finding out the pretrained model to "
"load."
msgstr ""
"训练后，您可以使用适配器的路径加载模型。我们建议您为预训练模型使用绝对路径。这是因为 LoRA "
"只保存适配器，并且适配器配置文件中的绝对路径用于查找要加载的预训练模型。"

#: ../../source/finetune/fintune.md:147 e0abd49455614a1f81611d5ed617ca45
msgid "Model Fine-tuning Memory Usage Statistics"
msgstr "模型微调显存占用统计"

#: ../../source/finetune/fintune.md:149 c04e3a983c6942b4ace8b5ce551c6746
msgid ""
"The following table presents the memory usage of the model when fine-"
"tuning using NVIDIA A100 (80GiB) GPUs under different numbers of GPUs. "
"The fine-tuning was performed with the DeepSpeed Zero-3 optimization, "
"Gradient Checkpointing techniques and offloading optimizer as well as "
"parameters memory to cpu, with a maximum length set to 2048 and batch "
"size set to 1. You refer to [deepspeed zero "
"stage](https://huggingface.co/docs/transformers/v4.41.2/en/deepspeed#select-a"
"-zero-stage) to reduce memory cost."
msgstr ""
"下表展示了在使用不同数量的 NVIDIA A100 (80GiB) GPU 进行微调时模型的显存占用情况。微调使用了 DeepSpeed "
"Zero-3 优化、梯度检查点技术以及将优化器和参数内存卸载到 CPU 的方法，最大长度设置为 2048，批处理大小设置为 1。您可以参考 "
"[deepspeed zero "
"stage](https://huggingface.co/docs/transformers/v4.41.2/en/deepspeed#select-a"
"-zero-stage) 来降低显存成本。"

#: ../../source/finetune/fintune.md:3 c07644417ab2437881daac7c854fa780
msgid "Fine-tuning Method"
msgstr "微调方法"

#: ../../source/finetune/fintune.md:3 577e6b1e127947c3805854a305975dfc
msgid "GPUs: 2"
msgstr "GPU 数量：2"

#: ../../source/finetune/fintune.md:3 d2e6bfcb92c74884ab88a5a806a99ab6
msgid "GPUs: 4"
msgstr "GPU 数量：4"

#: ../../source/finetune/fintune.md:3 088eaacfc23b44949eeb7ed4303f92c2
msgid "GPUs: 8"
msgstr "GPU 数量：8"

#: ../../source/finetune/fintune.md:3 543e2b3f9bf94bcf965b124881328584
msgid "LoRA Fine-tuning"
msgstr "LoRA 微调"

#: ../../source/finetune/fintune.md:3 3ae7172e721746f5912e792feb553a01
msgid "14.4 GiB"
msgstr "14.4 GiB"

#: ../../source/finetune/fintune.md:3 30550029e6b4470194f0926983ef6942
msgid "13.6 GiB"
msgstr "13.6 GiB"

#: ../../source/finetune/fintune.md:3 e2890f4bd3d14ead9aa70c4d3fa73c85
msgid "13.1 GiB"
msgstr "13.1 GiB"

#: ../../source/finetune/fintune.md:3 b6f6dd81999248a3865d6919611cdb67
msgid "Full Parameters Fine-tuning"
msgstr "全参数微调"

#: ../../source/finetune/fintune.md:3 b8ec9db09a3c4a84800cdbcb4af8da46
msgid "16.0 GiB"
msgstr "16.0 GiB"

#: ../../source/finetune/fintune.md:3 701f1d0befae42eab8166af93052a648
msgid "15.8 GiB"
msgstr "15.8 GiB"

#: ../../source/finetune/fintune.md:3 b6dc6f19319a49c1bf23fecd30455606
msgid "15.63GiB"
msgstr "15.63GiB"

#: ../../source/finetune/fintune.md:156 dd4d0a97c26045758ed426e98a33143f
msgid "Notes"
msgstr "注释"

#: ../../source/finetune/fintune.md:157 6570a3c0f8c648cdb5c2521e8817e782
msgid ""
"**Fine-tuning Method**: Displays two different fine-tuning strategies, "
"LoRA fine-tuning and Full parameters fine-tuning."
msgstr "**微调方法**：显示两种不同的微调策略，LoRA 微调和全参数微调。"

#: ../../source/finetune/fintune.md:158 69fe0596303445ed87396c50a22f5549
msgid ""
"**Number of GPUs**: The table lists the memory usage for configurations "
"with 2, 4, and 8 GPUs."
msgstr "**GPU 数量**：该表列出了使用 2、4 和 8 个 GPU 配置时的显存占用情况。"

#: ../../source/finetune/fintune.md:159 26f4d50389fa4869ac0ae391181fc128
msgid ""
"**Memory Usage**: Expressed in GiB, this shows the required memory for "
"each fine-tuning method under corresponding GPU configurations."
msgstr "**显存占用**：以 GiB 为单位，显示了每种微调方法在相应 GPU 配置下所需的显存。"

#: ../../source/finetune/fintune.md:160 27b21feac4634ba79f7f315308798deb
msgid ""
"**Out of memory**: Indicates that the memory was insufficient for full "
"parameters fine-tuning under the current GPU configurations."
msgstr "**内存不足**：表示在当前 GPU 配置下，全参数微调的内存不足。"

#: ../../source/finetune/fintune.md:162 4fe45fa3663b4fc8b4146d3ae9ccab7b
msgid "Finetuning FAQs"
msgstr "微调常见问题解答"

#: ../../source/finetune/fintune.md:164 d8cd7ad0473e4057a8cf316d93fd8925
msgid ""
"**Q:** When you encounter Out of Memory (OOM) issues during training "
"large models, you can try the following methods to resolve or mitigate "
"the issue:</summary>"
msgstr "**问：** 当您在训练大模型时遇到内存不足（OOM）问题时，可以尝试以下方法来解决或缓解该问题：</summary>"

#: ../../source/finetune/fintune.md:166 bfcc023ae4934bffba954f1f583e005d
msgid ""
"**A:** When you face Out of Memory (OOM) issues during training large "
"models, the following strategies may help resolve or mitigate the "
"problem:"
msgstr "**答：** 当您在训练大模型时遇到内存不足（OOM）问题时，以下策略可能有助于解决或缓解问题："

#: ../../source/finetune/fintune.md:168 c57c9f56360946d9b061d410bdcd226a
msgid "**Adjust Model Hyperparameters**"
msgstr "**调整模型超参数**"

#: ../../source/finetune/fintune.md:169 fbd6495f44ae4f64b99ee5a952dca454
msgid ""
"**Reduce `max_model_length`**: Decreasing the maximum sequence length the"
" model processes can significantly reduce the memory required for each "
"operation. For example, reducing the maximum length from 2048 to 1200 or "
"another value suitable for your dataset."
msgstr ""
"**减少 `max_model_length`**：降低模型处理的最大序列长度可以显著减少每次操作所需的内存。例如，将最大长度从 2048 减少到"
" 1200 或其他适合您数据集的值。"

#: ../../source/finetune/fintune.md:174 839683776eb141ddb177f1ee09c8efcc
msgid ""
"**Lower `batch_size`**: Reducing the amount of data processed in each "
"batch helps decrease memory consumption."
msgstr "**降低 `batch_size`**：减少每个批次处理的数据量有助于降低内存消耗。"

#: ../../source/finetune/fintune.md:178 4b8cfbe5399d445792ba43cce4185d85
msgid ""
"**Reduce the number of slices (`slice`)**: When handling large datasets "
"such as large images files, reducing the number of slices processed each "
"time can lower memory requirements."
msgstr "**减少切片数量 (`slice`)**：在处理大型数据集（如大型图像文件）时，减少每次处理的切片数量可以降低内存需求。"

#: ../../source/finetune/fintune.md:183 1be2c721fcce4ddeb026ba6993ea0c4c
msgid "**Reduce Training Model Parameters**"
msgstr "**减少训练模型参数**"

#: ../../source/finetune/fintune.md:184 a12fb90c86b24ecda7c7355442fd67f9
msgid ""
"**Do not train VPM (Visual Processing Module)**: You can adjust "
"hyperparameters in the finetune script to opt out of training the visual "
"processing module to save memory."
msgstr "**不训练 VPM（视觉处理模块）**：您可以在微调脚本中调整超参数，选择不训练视觉处理模块以节省内存。"

#: ../../source/finetune/fintune.md:188 b15e3c84ea884e2083d7456843fb68de
msgid "**Use LoRA finetuning**: Refer to the LoRA finetuning section."
msgstr "**使用 LoRA 微调**：请参考 LoRA 微调部分。"

#: ../../source/finetune/fintune.md:190 d877f006441443dcaa13074ac4b7968e
msgid "**Optimize with DeepSpeed**"
msgstr "**使用 DeepSpeed 优化**"

#: ../../source/finetune/fintune.md:191 5111df8859094d9ab147ba3b2bb941b3
msgid ""
"**Configure DeepSpeed Zero Stage 2**: Use the following configuration to "
"offload optimizer parameters to the CPU, reducing memory pressure on the "
"GPU:"
msgstr "**配置 DeepSpeed Zero Stage 2**：使用以下配置将优化器参数卸载到 CPU，以减少 GPU 上的内存压力："

#: ../../source/finetune/fintune.md:200 c391bc0d628d4731ae6fda937b4c8504
msgid ""
"**Configure DeepSpeed Zero Stage 3**：Further offload model parameters and"
" optimizer parameters to the CPU, further reducing GPU memory usage:"
msgstr "**配置 DeepSpeed Zero Stage 3**：进一步将模型参数和优化器参数卸载到 CPU，从而进一步减少 GPU 内存使用："

#: ../../source/finetune/fintune.md:214 94b1653d8c8e4f12929b0f7f966c5a4e
msgid ""
"You can visit [huggingface "
"deepspeed](https://huggingface.co/docs/transformers/deepspeed) to find "
"out more about how to use DeepSpeed."
msgstr ""
"您可以访问 [huggingface "
"deepspeed](https://huggingface.co/docs/transformers/deepspeed) 了解更多关于如何使用"
" DeepSpeed 的信息。"

#: ../../source/finetune/fintune.md:216 ab5ddb2fb3414affb970e525ca1ac185
msgid ""
"**Q:** Encounter an error while using the AutoPeftModelForCausalLM to "
"load a checkpoint that has undergone lora fine-tuning</summary>"
msgstr "**问：** 在使用 AutoPeftModelForCausalLM 加载经过 lora 微调的检查点时遇到错误</summary>"

#: ../../source/finetune/fintune.md:218 22dece83bb344886916ff414a1b4d254
msgid ""
"**A:** The error as described in [issues "
"168](https://github.com/OpenBMB/MiniCPM-V/issues/168) occurs because the "
"model lacks `get_input_embeddings` and `set_input_embeddings` methods. "
"Follow these steps to resolve this issue:"
msgstr ""
"**答：** 如 [issues 168](https://github.com/OpenBMB/MiniCPM-V/issues/168) "
"中所述的错误发生，是因为模型缺少 `get_input_embeddings` 和 `set_input_embeddings` "
"方法。请按照以下步骤解决此问题："

#: ../../source/finetune/fintune.md:220 f80c8742896e4d0298bb017cfd4c1831
msgid ""
"1.**Reload the Fine-Tuned Model:** Make sure you correctly load the "
"checkpoint that has been fine-tuned using lora techniques. Use the "
"following code example to guide you:"
msgstr "1.**重新加载微调后的模型：** 确保您正确加载了使用 lora 技术微调过的检查点。请使用以下代码示例作为指导："

#: ../../source/finetune/fintune.md:233 916882ba49c84d91b6f4a00241fc4e1d
msgid "2.**Update the `model_minicpmv.py` File:**"
msgstr "2.**更新 `model_minicpmv.py` 文件：**"

#: ../../source/finetune/fintune.md:234 7e46a9cdcd7443f78af86e26b0d37cb8
msgid ""
"**Verification:** Make sure you verify and update your "
"`model_minicpmv.py` file to ensure it is the latest version."
msgstr "**验证：** 确保您验证并更新您的 `model_minicpmv.py` 文件，以确保其为最新版本。"

#: ../../source/finetune/fintune.md:235 6a8a480a26c8466999a07b462721a328
msgid ""
"**Update Hugging Face Library Code:** If the issue persists after "
"updating the file, consider updating the related code in the Hugging Face"
" library."
msgstr "**更新 Hugging Face 库代码：** 如果更新文件后问题仍然存在，请考虑更新 Hugging Face 库中的相关代码。"

#: ../../source/finetune/fintune.md:236 7eb26f875dbb437b90fada9ca09b82f6
msgid ""
"**Direct File Copy:** For a quick resolution, directly download and copy "
"the latest `model_minicpmv.py` file into your project. This file is "
"available from the following sources:"
msgstr ""
"**直接复制文件：** 为了快速解决问题，请直接下载最新的 `model_minicpmv.py` "
"文件并将其复制到您的项目中。该文件可从以下来源获取："

#: ../../source/finetune/fintune.md:237 de25a05ef0604173a1dbe1ee74e5b7cc
msgid ""
"[MiniCPM-Llama3-V-2_5 on Hugging Face](https://huggingface.co/openbmb"
"/MiniCPM-Llama3-V-2_5/tree/main)"
msgstr ""
"[Hugging Face 上的 MiniCPM-Llama3-V-2_5](https://huggingface.co/openbmb"
"/MiniCPM-Llama3-V-2_5/tree/main)"

#: ../../source/finetune/fintune.md:238 2133cd7ac2f44bc48f2fcf3bb126b4a2
msgid "[MiniCPM-V-2 on Hugging Face](https://huggingface.co/openbmb/MiniCPM-V-2)"
msgstr "[Hugging Face 上的 MiniCPM-V-2](https://huggingface.co/openbmb/MiniCPM-V-2)"

#: ../../source/finetune/fintune.md:240 ea9a386ee8924d3db2faedb3ac8cda56
msgid ""
"**Q:** How do I use the `flash_attention_2` implementation when loading a"
" pretrained model?</summary>"
msgstr "**问：** 加载预训练模型时如何使用 `flash_attention_2` 实现？</summary>"

#: ../../source/finetune/fintune.md:242 2052ba72df1f43e484db66c631e9431f
msgid ""
"**A:** If your environment supports `flash_attn2`, you can add an "
"argument `_attn_implementation=\"flash_attention_2\"` when using the "
"`AutoModel.from_pretrained` method to load a model. For example:"
msgstr ""
"**答：** 如果您的环境支持 `flash_attn2`，您可以在使用 `AutoModel.from_pretrained` "
"方法加载模型时添加参数 `_attn_implementation=\"flash_attention_2\"`。例如："

#: ../../source/finetune/fintune.md:248 7ae47a5ec8b747c7ae01d8fb2424acba
msgid ""
"**Q:** What if our data is resized to 512? Can we use the original image "
"size instead?</summary>"
msgstr "**问：** 如果我们的数据被调整到 512 大小怎么办？我们可以使用原始图像尺寸吗？</summary>"

#: ../../source/finetune/fintune.md:250 19f473acd2e240c4a986e096316757f9
msgid ""
"**A:** Our model supports up to 1344x1344 lossless encoding. If you are "
"currently resizing your images to 512, you might want to try using the "
"original image sizes instead. Our system automatically includes a high-"
"definition image encoding scheme by default."
msgstr ""
"**答：** 我们的模型支持高达 1344x1344 的无损编码。如果您目前将图像大小调整为 "
"512，您可能想尝试使用原始图像尺寸。我们的系统默认自动包含高清图像编码方案。"

#: ../../source/finetune/fintune.md:252 bbe38df21520472c89d730316c6a6afa
msgid ""
"**Q:** What should we do if we encounter out-of-memory (OOM) "
"errors?</summary>"
msgstr "**问：** 如果我们遇到内存不足（OOM）错误该怎么办？</summary>"

#: ../../source/finetune/fintune.md:254 42fe5a877a524b95a60a64d799118b70
msgid ""
"**A:** If you experience OOM issues, consider reducing the batch size "
"(`bs`). To maintain an equivalent total batch size, you can adjust the "
"`gradient_accumulation_steps` setting. This approach allows you to manage"
" memory usage effectively while still processing the desired amount of "
"data per training step."
msgstr ""
"**答：** 如果您遇到 OOM 问题，请考虑减小批处理大小（`bs`）。为了保持等效的总批处理大小，您可以调整 "
"`gradient_accumulation_steps` 设置。这种方法可以有效地管理内存使用，同时仍然在每个训练步骤中处理所需的数据量。"

#: ../../source/finetune/fintune.md:256 abe9be3199284bb7b22752de2124f7bc
msgid ""
"**Q:** How can we determine the maximum length for our training data, and"
" what if we do not want to train the vision encoder?</summary>"
msgstr "**问：** 我们如何确定训练数据的最大长度，以及如果我们不想训练视觉编码器该怎么办？</summary>"

#: ../../source/finetune/fintune.md:258 2f1dcf895d694c84bf9d4baaaef2203a
msgid ""
"**A:** I recommend using this function "
"[here](https://github.com/OpenBMB/MiniCPM-V/blob/main/finetune/dataset.py#L220)"
" to sample the length of your training data. Note that the `input_ids` "
"length includes the image portion. Once you determine the maximum length,"
" you can specify it in the startup command using `--model_max_length "
"xxx`."
msgstr ""
"**答：** "
"我建议使用[此处](https://github.com/OpenBMB/MiniCPM-V/blob/main/finetune/dataset.py#L220)的函数来抽样您的训练数据长度。请注意，`input_ids`"
" 的长度包括图像部分。一旦确定了最大长度，您可以在启动命令中使用 `--model_max_length xxx` 来指定它。"

#: ../../source/finetune/fintune.md:260 bae8f4e587904927811901071bd5876f
msgid ""
"Additionally, if you prefer not to train the vision encoder, you can add "
"`--tune_vision false` to your command."
msgstr "此外，如果您不想训练视觉编码器，可以在命令中添加 `--tune_vision false`。"

#: ../../source/finetune/fintune.md:262 b17755795c184917a1e94bfd791b2e3f
msgid ""
"**Q:** How can we adjust training hyperparameters when using LoRA to "
"train our model?</summary>"
msgstr "**问：** 当使用 LoRA 训练模型时，我们如何调整训练超参数？</summary>"

#: ../../source/finetune/fintune.md:264 687894ae52524c8099849f30d964d9a2
msgid ""
"**A:** You can refer to the [LoRA "
"documentation](https://huggingface.co/docs/peft/en/package_reference/lora#peft.LoraConfig)"
" for guidance on adjusting your training hyperparameters when using LoRA."
" This documentation provides detailed information on configuring various "
"parameters specific to the LoRA adaptation technique."
msgstr ""
"**答：** 您可以参考 [LoRA "
"文档](https://huggingface.co/docs/peft/en/package_reference/lora#peft.LoraConfig)来获取有关在使用"
" LoRA 时调整训练超参数的指导。该文档提供了有关配置 LoRA 适应技术特定各种参数的详细信息。"

#: ../../source/finetune/fintune.md:267 a53d72b179f442a99e5b14e75dcc5e5f
msgid "Customizing Hyperparameters"
msgstr "自定义超参数"

#: ../../source/finetune/fintune.md:268 ed5246913a0f4d5e94a5105f274d4074
msgid ""
"To tailor the training process according to your specific requirements, "
"you can adjust various hyperparameters. For comprehensive documentation "
"on available hyperparameters and their functionalities, you can refer to "
"the [official Transformers "
"documentation](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)"
" and [Lora "
"documentation](https://huggingface.co/docs/peft/en/package_reference/lora#peft.LoraConfig)."
" Experimentation and fine-tuning of these parameters are essential for "
"achieving optimal model performance tailored to your specific task and "
"dataset."
msgstr ""
"为了根据您的特定需求定制训练过程，您可以调整各种超参数。有关可用超参数及其功能的全面文档，您可以参考 [官方 Transformers "
"文档](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)和"
" [Lora "
"文档](https://huggingface.co/docs/peft/en/package_reference/lora#peft.LoraConfig)。对这些参数进行实验和微调对于实现针对您的特定任务和数据集优化的最佳模型性能至关重要。"

