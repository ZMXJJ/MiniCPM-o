# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, OpenBMB
# This file is distributed under the same license as the MiniCPM-o Cookbook
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MiniCPM-o Cookbook \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-07-16 14:54+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/training/llamafactory.md:1 743975c370c44f7a8db1320a02408428
msgid "Llama Factory"
msgstr "Llama Factory"

#: ../../source/training/llamafactory.md:3 a7c01b6c6be64a259ad7ca356ea97f46
msgid "Install LlamaFactory"
msgstr "安装 Llama Factory"

#: ../../source/training/llamafactory.md:5 1c581d8cc5c344f6adfc0a3c7e031661
msgid "Clone the LlamaFactory GitHub repository:"
msgstr "从克隆Llama Factory Github仓库代码"

#: ../../source/training/llamafactory.md:11 02c4e7df081d412c8d8fe4f5910456fa
msgid "Install LlamaFactory dependencies:"
msgstr "安装依赖"

#: ../../source/training/llamafactory.md:18 a6437aa7c0844caca35186b4545a9a05
msgid "Prepare the Dataset"
msgstr "准备数据集"

#: ../../source/training/llamafactory.md:20 a936ff44f81b45fda7ef7854abb63ce8
msgid ""
"Refer to the **mllm_demo.json** dataset under [LLaMA-"
"Factory/data](https://github.com/hiyouga/LLaMA-"
"Factory/blob/main/data/dataset_info.json) and construct your data in the "
"same format. The structure is as follows:"
msgstr ""
"参考 [LLaMA-Factory/data](https://github.com/hiyouga/LLaMA-Factory/blob/main/data/dataset_info.json) 下的 **mllm_demo.json** 数据集，按照相同格式构建你的数据。结构如下："

#: ../../source/training/llamafactory.md:22 02dd689ccf04452b9c1061264180f583
msgid ""
"To use images in multi-turn conversations, add the `<image>` tag in the "
"user's content for each turn, and add the corresponding image paths in "
"the `images` field. The number of `<image>` tags should match the number "
"of values in `images`."
msgstr ""
"如需在多轮对话中使用图片，请在每轮用户内容中添加 `<image>` 标签，并在 `images` 字段中添加对应的图片路径。`<image>` 标签的数量应与 `images` 字段中的值数量一致。"

#: ../../source/training/llamafactory.md:76 13d59679ba3643aa890253b815ec523c
msgid ""
"Name your constructed JSON file as `image_caption.json` and place it "
"under `LLaMA-Factory/data/`."
msgstr "将你构建的 JSON 文件命名为 `image_caption.json`，并放置在 `LLaMA-Factory/data/` 目录下。"

#: ../../source/training/llamafactory.md:78 da9913915150498da4cb191fd444d5e7
msgid "Locate `LLaMA-Factory/data/dataset_info.json`."
msgstr "定位到 `LLaMA-Factory/data/dataset_info.json` 文件。"

#: ../../source/training/llamafactory.md:80 b86bf00014c246efabed357aa838a026
msgid "Search for `mllm_demo` and find the following field:"
msgstr "查找 `mllm_demo` 字段，并找到如下内容："

#: ../../source/training/llamafactory.md:92 d20d07e8334442a3809cb1d6ea606908
msgid ""
"Copy this field, modify the highlighted parts as per your dataset, and "
"add it to `LLaMA-Factory/data/dataset_info.json`."
msgstr "复制该字段，根据你的数据集修改高亮部分，并添加到 `LLaMA-Factory/data/dataset_info.json` 文件中。"

#: ../../source/training/llamafactory.md:94 da64684b200446948f1a0b18368d2207
msgid ""
"Change the **key** `mllm_demo` to your custom dataset name, e.g., "
"`cpmv_img`."
msgstr "将 **键值** `mllm_demo` 修改为你的自定义数据集名称，例如 `cpmv_img`。"

#: ../../source/training/llamafactory.md:96 fc1e7194eb7643dba2f149db997453e5
msgid ""
"Change the `file_name` value to your constructed dataset name, e.g., "
"`image_caption.json`."
msgstr "将 `file_name` 的值修改为你构建的数据集名称，例如 `image_caption.json`。"

#: ../../source/training/llamafactory.md:98 3fe2726423bb4b4c83c9c61847d0f23f
msgid "Example:"
msgstr "示例："

#: ../../source/training/llamafactory.md:110 438b1b7b568b4d7fa9df593132abc525
msgid "Create Training Configuration YAML Files"
msgstr "创建训练配置 YAML 文件"

#: ../../source/training/llamafactory.md:112 8764ccb374064b4e9444d830b8c1e051
msgid "LoRA Fine-tuning"
msgstr "LoRA 微调"

#: ../../source/training/llamafactory.md:114 8021ff99d75243d7a45bf37cd05cd377
msgid ""
"Create a configuration file named `minicpmv_4_lora_sft.yaml` and place it"
" in `LLaMA-Factory/minicpm_config`."
msgstr "创建名为 `minicpmv_4_lora_sft.yaml` 的配置文件，并放置在 `LLaMA-Factory/minicpm_config` 目录下。"

#: ../../source/training/llamafactory.md:158 9bd83b271d9548dabf7cc2d4ccd61c21
msgid "Full Fine-tuning"
msgstr "全量微调"

#: ../../source/training/llamafactory.md:160 06baf87e6ae2442a9f60ef61604273e8
msgid ""
"Create a full training configuration file `minicpmv_4_full_sft.yaml` and "
"place it in `LLaMA-Factory/minicpm_config`:"
msgstr "创建全量训练配置文件 `minicpmv_4_full_sft.yaml`，并放置在 `LLaMA-Factory/minicpm_config` 目录下："

#: ../../source/training/llamafactory.md:207 82cbe5c1e011402c9fa1160eb5c4406f
msgid "Model Training"
msgstr "模型训练"

#: ../../source/training/llamafactory.md:209 37bc04df9dfa4c118546dfaa4b11ad93
msgid "Full Training"
msgstr "全量训练"

#: ../../source/training/llamafactory.md:216 ffd6f5a2af824ff895d769f59332e841
msgid "LoRA Training"
msgstr "LoRA 训练"

#: ../../source/training/llamafactory.md:218 8015c13a53834cf9a7aef1c5f4a41c3f
msgid "Start training:"
msgstr "开始训练："

#: ../../source/training/llamafactory.md:224 7a94f1fbad284e869db439bdcab7b1cb
msgid "Create a merge script `merge.yaml`:"
msgstr "创建合并脚本 `merge.yaml`："

#: ../../source/training/llamafactory.md:241 715f558dd0e24ca180fb09d9254cb67c
msgid "Merge the model:"
msgstr "合并模型："
